---
title: Configuration
description: LLM providers, model tiers, and environment variables
icon: gear
---

All configuration lives in `.env` at your workspace root. The setup wizard (`octo init`) generates this file, or you can create it manually from [`.env.example`](https://github.com/onetest-ai/Octo/blob/main/.env.example).

## LLM Providers

Octo supports 5 providers. You only need to configure **one**.

<Tabs>
  <Tab title="Anthropic">
    The simplest option — direct API access to Claude models.

    ```env
    ANTHROPIC_API_KEY=sk-ant-...
    DEFAULT_MODEL=claude-sonnet-4-5-20250929
    ```
  </Tab>

  <Tab title="AWS Bedrock">
    Uses Claude models via AWS. Requires AWS credentials with Bedrock access.

    ```env
    AWS_REGION=us-east-1
    AWS_ACCESS_KEY_ID=...
    AWS_SECRET_ACCESS_KEY=...
    DEFAULT_MODEL=us.anthropic.claude-sonnet-4-5-20250929-v1:0
    ```

    <Note>
    Bedrock model IDs include a region prefix (`us.`, `eu.`) and version suffix (`:0`).
    </Note>
  </Tab>

  <Tab title="OpenAI">
    ```env
    OPENAI_API_KEY=sk-...
    DEFAULT_MODEL=gpt-4o
    ```
  </Tab>

  <Tab title="Azure OpenAI">
    ```env
    AZURE_OPENAI_API_KEY=...
    AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
    AZURE_OPENAI_API_VERSION=2024-12-01-preview
    DEFAULT_MODEL=gpt-4o
    ```
  </Tab>

  <Tab title="GitHub Models">
    Free tier available with a GitHub PAT.

    ```env
    GITHUB_TOKEN=ghp_...
    DEFAULT_MODEL=github/openai/gpt-4.1
    ```

    GitHub Models auto-routes to the right LangChain class:
    - `github/claude-*` → ChatAnthropic
    - Everything else → ChatOpenAI
  </Tab>
</Tabs>

## Auto-Detection

The model factory auto-detects the provider from the model name:

| Model name pattern | Provider |
|---|---|
| `github/*` | GitHub Models |
| `eu.anthropic.*`, `us.anthropic.*` | AWS Bedrock |
| `claude-*` | Anthropic direct |
| `gpt-*`, `o1-*`, `o3-*` | OpenAI |
| `gpt-*` + `AZURE_OPENAI_ENDPOINT` set | Azure OpenAI |

Override with `LLM_PROVIDER` if needed:

```env
LLM_PROVIDER=bedrock  # anthropic | bedrock | openai | azure | github
```

## Model Tiers

Octo uses three tiers to balance cost vs quality. Different agents use different tiers:

| Tier | Used For | Example |
|---|---|---|
| **HIGH** | Complex reasoning, architecture, multi-step planning | `claude-opus-4-5-20250929` |
| **DEFAULT** | Supervisor routing, general chat, tool use | `claude-sonnet-4-5-20250929` |
| **LOW** | Summarization, simple workers, cost-sensitive tasks | `claude-haiku-4-5-20251001` |

```env
DEFAULT_MODEL=claude-sonnet-4-5-20250929
HIGH_TIER_MODEL=claude-opus-4-5-20250929
LOW_TIER_MODEL=claude-haiku-4-5-20251001
```

## Model Profiles

Profiles are presets that map tiers to agent roles:

| Profile | Supervisor | Workers | High-tier agents |
|---|---|---|---|
| `quality` | high | default | high |
| `balanced` | default | low | high |
| `budget` | low | low | default |

```env
MODEL_PROFILE=balanced
```

Switch at runtime with `/profile <name>`.

## Agent Directories

Load agents from external projects by pointing to their AGENT.md directories:

```env
AGENT_DIRS=/path/to/project-a/.claude/agents:/path/to/project-b/.claude/agents
```

Colon-separated. Each directory is scanned for `*/AGENT.md` files.

## Middleware Tuning

```env
# Max chars for a single tool result before truncation
TOOL_RESULT_LIMIT=40000

# Context window summarization triggers (whichever fires first)
SUMMARIZATION_TRIGGER_FRACTION=0.7
SUMMARIZATION_TRIGGER_TOKENS=100000

# Tokens of recent history to keep after summarization
SUMMARIZATION_KEEP_TOKENS=20000

# Supervisor per-message char limit
SUPERVISOR_MSG_CHAR_LIMIT=30000
```

## MCP Servers

MCP server configuration lives in `.mcp.json`. See [`.mcp.json.example`](https://github.com/onetest-ai/Octo/blob/main/.mcp.json.example) for a template, and [MCP Servers](/features/mcp-servers) for management commands.

## Next Steps

<CardGroup cols={2}>
  <Card title="Telegram Setup" icon="paper-plane" href="/getting-started/telegram-setup">
    Add Telegram transport
  </Card>
  <Card title="Model Profiles" icon="sliders" href="/guides/model-profiles">
    Fine-tune cost vs quality
  </Card>
</CardGroup>
